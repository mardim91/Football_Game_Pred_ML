{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "import math\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def drop_players_columns(match_df):\n",
    "    match_df = match_df[match_df.columns.drop(list(match_df.filter(regex='player')))]\n",
    "    return match_df\n",
    "\n",
    "def keep_certain_bookeepers(match_df):\n",
    "    # In this function we will keep only the Bet365 and Bwin collumns\n",
    "    # because they are the most popular bookeepers\n",
    "    \n",
    "    col_list = match_df.columns.tolist()\n",
    "    cols_to_use = col_list[:len(col_list)-24]\n",
    "    match_df = match_df[cols_to_use]\n",
    "    return match_df\n",
    "\n",
    "def create_class_label(match_df):\n",
    "    #Home Win = 1\n",
    "    #Home Defeat = -1\n",
    "    #Draw = 0\n",
    "    conditions = [(match_df['home_team_goal'] > match_df['away_team_goal']),\n",
    "                  (match_df['home_team_goal'] < match_df['away_team_goal'])]\n",
    "\n",
    "    choices = [1, -1]\n",
    "\n",
    "    match_df['result'] = np.select(conditions, choices, default=0)\n",
    "    return match_df\n",
    "\n",
    "def calculate_total_goals(match_df):\n",
    "    #This function calculates total gols fromthe sum\n",
    "    #of home and away goals. We do that because currently\n",
    "    #the goals are in xml format which is not helpful\n",
    "    \n",
    "    match_df = match_df.drop(['goal'],axis=1)\n",
    "    match_df['total_goals'] = match_df['home_team_goal'] + match_df['away_team_goal']\n",
    "    return match_df\n",
    "\n",
    "def parse_xml_columns(match_df):\n",
    "    match_df['home_shoton'] = 0\n",
    "    match_df['away_shoton'] = 0\n",
    "    match_df['home_shotoff'] = 0\n",
    "    match_df['away_shotoff'] = 0\n",
    "    match_df['home_fouls'] = 0\n",
    "    match_df['away_fouls'] = 0\n",
    "    match_df['home_corner'] = 0\n",
    "    match_df['away_corner'] = 0\n",
    "    match_df['home_ycard'] = 0\n",
    "    match_df['away_ycard'] = 0\n",
    "    match_df['home_rcard'] = 0\n",
    "    match_df['away_rcard'] = 0\n",
    "    match_df['home_cross'] = 0\n",
    "    match_df['away_cross'] = 0\n",
    "    match_df['home_possession'] = 0.0\n",
    "    match_df['away_possession'] = 0.0\n",
    "    \n",
    "    for index, row in match_df.iterrows():\n",
    "        home_team = row['home_team_api_id']\n",
    "        away_team = row['away_team_api_id'] \n",
    "        \n",
    "        root_shoton = ET.fromstring(row['shoton'])\n",
    "        root_shotoff = ET.fromstring(row['shotoff'])\n",
    "        root_foulcommit = ET.fromstring(row['foulcommit'])\n",
    "        root_corner = ET.fromstring(row['corner'])\n",
    "        root_card = ET.fromstring(row['card'])\n",
    "        root_cross = ET.fromstring(row['cross'])\n",
    "        root_possession = ET.fromstring(row['possession'])\n",
    "        \n",
    "        for value in root_shoton.findall('value'):\n",
    "            team = value.find('team')\n",
    "            if team is None:\n",
    "                continue\n",
    "            if (team.text == str(home_team)):\n",
    "                match_df.at[index,'home_shoton'] = match_df.at[index,'home_shoton']+1\n",
    "            if (team.text == str(away_team)):\n",
    "                match_df.at[index,'away_shoton'] = match_df.at[index,'away_shoton']+1\n",
    "                \n",
    "        for value in root_shotoff.findall('value'):\n",
    "            team = value.find('team')\n",
    "            if team is None:\n",
    "                continue\n",
    "            if (team.text == str(home_team)):\n",
    "                match_df.at[index,'home_shotoff'] = match_df.at[index,'home_shotoff']+1\n",
    "            if (team.text == str(away_team)):\n",
    "                match_df.at[index,'away_shotoff'] = match_df.at[index,'away_shotoff']+1\n",
    "                \n",
    "        for value in root_foulcommit.findall('value'):\n",
    "            team = value.find('team')\n",
    "            if team is None:\n",
    "                continue\n",
    "            if (team.text == str(home_team)):\n",
    "                match_df.at[index,'home_fouls'] = match_df.at[index,'home_fouls']+1\n",
    "            if (team.text == str(away_team)):\n",
    "                match_df.at[index,'away_fouls'] = match_df.at[index,'away_fouls']+1\n",
    "                \n",
    "        for value in root_corner.findall('value'):\n",
    "            team = value.find('team')\n",
    "            if team is None:\n",
    "                continue\n",
    "            if (team.text == str(home_team)):\n",
    "                match_df.at[index,'home_corner'] = match_df.at[index,'home_corner']+1\n",
    "            if (team.text == str(away_team)):\n",
    "                match_df.at[index,'away_corner'] = match_df.at[index,'away_corner']+1\n",
    "                \n",
    "        if root_card.findall('value'):           \n",
    "            for value in root_card.findall('value'):\n",
    "                card_type = value.find('comment').text\n",
    "                team = value.find('team')\n",
    "                if team is None:\n",
    "                    continue\n",
    "                if (team.text == str(home_team)):\n",
    "                    if card_type in ['r', 'y2']:\n",
    "                        match_df.at[index,'home_rcard'] = match_df.at[index,'home_rcard']+1\n",
    "                    if card_type == 'y':\n",
    "                        match_df.at[index,'home_ycard'] = match_df.at[index,'home_ycard']+1\n",
    "                if (team.text == str(away_team)):\n",
    "                    if card_type in ['r', 'y2']:\n",
    "                        match_df.at[index,'away_rcard'] = match_df.at[index,'away_rcard']+1\n",
    "                    if card_type == 'y':\n",
    "                        match_df.at[index,'away_ycard'] = match_df.at[index,'away_ycard']+1\n",
    "                        \n",
    "        for value in root_cross.findall('value'):\n",
    "            cross_type = value.find('type').text\n",
    "            team = value.find('team')\n",
    "            if team is None:\n",
    "                continue\n",
    "            if cross_type != 'cross':\n",
    "                continue\n",
    "            if (team.text == str(home_team)):\n",
    "                match_df.at[index,'home_cross'] = match_df.at[index,'home_cross']+1\n",
    "            if (team.text == str(away_team)):\n",
    "                match_df.at[index,'away_cross'] = match_df.at[index,'away_cross']+1\n",
    "        value_list_len = float(len(root_possession.findall('value')))\n",
    "        if value_list_len != 0:\n",
    "            home_pos_sum = 0\n",
    "            away_pos_sum = 0\n",
    "            for value in root_possession.findall('value'):\n",
    "                homepos = value.find('homepos')\n",
    "                awaypos = value.find('awaypos')\n",
    "                if (homepos is None) or (awaypos is None):\n",
    "                    value_list_len = value_list_len - 1\n",
    "                    continue\n",
    "                home_pos_sum = home_pos_sum + int(homepos.text)\n",
    "                away_pos_sum = away_pos_sum + int(awaypos.text)\n",
    "            match_df.at[index,'home_possession'] = round((home_pos_sum/value_list_len),2)\n",
    "            match_df.at[index,'away_possession'] = round((away_pos_sum/value_list_len),2)\n",
    "        else:\n",
    "            match_df.at[index,'home_possession'] = 50\n",
    "            match_df.at[index,'away_possession'] = 50\n",
    "    match_df = match_df.drop(['shoton','shotoff','foulcommit','card','cross','corner','possession'], axis = 1)\n",
    "            \n",
    "    return match_df\n",
    "\n",
    "def calculate_ma_ca_elo(match_df,teams_list):\n",
    "    team_df_dict = dict()\n",
    "    for item in teams_list:\n",
    "        team_df = match_df.loc[(match_df['home_team_api_id'] == item) | (match_df['away_team_api_id'] == item)]\n",
    "        team_df['goals'] = 0\n",
    "        team_df['shotons'] = 0\n",
    "        team_df['shotoffs'] = 0\n",
    "        team_df['fouls'] = 0\n",
    "        team_df['corners'] = 0\n",
    "        team_df['ycards'] = 0\n",
    "        team_df['rcards'] = 0\n",
    "        team_df['crosses'] = 0\n",
    "        team_df['possessions'] = 0.0\n",
    "        team_df['elo_rate'] = 0\n",
    "        for index, row in team_df.iterrows():\n",
    "            if row['home_team_api_id'] == item:\n",
    "                team_df.at[index,'goals'] = row['home_team_goal']\n",
    "                team_df.at[index,'shotons'] = row['home_shoton']\n",
    "                team_df.at[index,'shotoffs'] = row['home_shotoff']\n",
    "                team_df.at[index,'fouls'] = row['home_fouls']\n",
    "                team_df.at[index,'corners'] = row['home_corner']\n",
    "                team_df.at[index,'ycards'] = row['home_ycard']\n",
    "                team_df.at[index,'rcards'] = row['home_rcard']\n",
    "                team_df.at[index,'crosses'] = row['home_cross']\n",
    "                team_df.at[index,'possessions'] = row['home_possession']\n",
    "                team_df.at[index,'elo_rate'] = row['home_elo']\n",
    "            if row['away_team_api_id'] == item:\n",
    "                team_df.at[index,'goals'] = row['away_team_goal']\n",
    "                team_df.at[index,'shotons'] = row['away_shoton']\n",
    "                team_df.at[index,'shotoffs'] = row['away_shotoff']\n",
    "                team_df.at[index,'fouls'] = row['away_fouls']\n",
    "                team_df.at[index,'corners'] = row['away_corner']\n",
    "                team_df.at[index,'ycards'] = row['away_ycard']\n",
    "                team_df.at[index,'rcards'] = row['away_rcard']\n",
    "                team_df.at[index,'crosses'] = row['away_cross']\n",
    "                team_df.at[index,'possessions'] = row['away_possession']\n",
    "                team_df.at[index,'elo_rate'] = row['away_elo']\n",
    "        #print(team_df[['home_team_api_id','home_team_goal','away_team_goal','goals']])\n",
    "        for col in ['goals','shotons','shotoffs', 'fouls', 'corners','ycards','rcards','crosses','possessions']:\n",
    "            #prepei na ta shiftarw ola kata ena wste to ma kai ca olwn ton prwhgoumenwn agwnwn na erthei ston shmerino\n",
    "            team_df['ma_'+col] = team_df[col].rolling(window=5).mean()\n",
    "            team_df['ca_'+col] = team_df[col].expanding().mean()\n",
    "            team_df['ma_pow2_'+col] = np.power((team_df['ma_'+col]),2)\n",
    "            team_df['ca_pow2_'+col] = np.power((team_df['ca_'+col]),2)\n",
    "            team_df['ma_sqrt_'+col]=team_df['ma_'+col]**(1/2)\n",
    "            team_df['ca_sqrt_'+col]=team_df['ca_'+col]**(1/2)\n",
    "            \n",
    "        team_df_dict.update({str(item): team_df})\n",
    "        \n",
    "    return team_df_dict\n",
    "\n",
    "\n",
    "def shift_ma_ca_elo_columns(team_df_dict):\n",
    "    ca_ma_col_list = list()\n",
    "    for team in team_df_dict:\n",
    "        for col in team_df_dict[team].columns:\n",
    "            if ('ca_' in col) or ('ma_' in col) or ('elo_rate' in col):\n",
    "                if col not in ca_ma_col_list:\n",
    "                    ca_ma_col_list.append(col)\n",
    "                team_df_dict[team][col] = team_df_dict[team][col].shift(1)\n",
    "    \n",
    "    return team_df_dict, ca_ma_col_list\n",
    "\n",
    "def add_ca_ma_elo_col_to_main_df(team_shifted_dict, match_df,ca_ma_col_names):\n",
    "    for team in team_shifted_dict:\n",
    "        for index, team_row in team_shifted_dict[team].iterrows():\n",
    "            if team == str(team_row['home_team_api_id']):\n",
    "                for col in ca_ma_col_names:\n",
    "                    match_df.at[index,'home_'+col] = team_row[col]\n",
    "            if team == str(team_row['away_team_api_id']):\n",
    "                for col in ca_ma_col_names:\n",
    "                    match_df.at[index,'away_'+col] = team_row[col]\n",
    "\n",
    "    return match_df\n",
    "\n",
    "def create_unified_columns(match_df, is_home):\n",
    "\n",
    "    if is_home:\n",
    "        match_df = match_df.rename(columns={\"home_team_goal\": \"goals\"})\n",
    "        match_df = match_df.drop(columns=['away_team_goal'])\n",
    "        match_df['homegame'] = 1\n",
    "        for col in match_df.columns:\n",
    "            if (\"away_ma\" in col) or (\"away_ca\" in col) or (\"away_elo_rate\" in col) or (\"pr_perc_away_win\" in col) or (\"away_strength\" in col):\n",
    "                new_col = col.replace(\"away\",\"opponent\")\n",
    "                match_df = match_df.rename(columns={col: new_col})\n",
    "            if (\"home_ma\" in col) or (\"home_ca\" in col) or (\"home_elo_rate\" in col) or (\"pr_perc_home_win\" in col) or (\"home_strength\" in col):\n",
    "                new_col = col.replace(\"home\", \"team\")\n",
    "                match_df = match_df.rename(columns={col: new_col})\n",
    "    if not is_home:\n",
    "        match_df = match_df.rename(columns={\"away_team_goal\": \"goals\"})\n",
    "        match_df = match_df.drop(columns=['home_team_goal'])\n",
    "        match_df['homegame'] = 0\n",
    "        match_df['goals_diff'] = - match_df['goals_diff']\n",
    "        for col in match_df.columns:\n",
    "            if (\"home_ma\" in col) or (\"home_ca\" in col) or (\"home_elo_rate\" in col) or (\"pr_perc_home_win\" in col) or (\"home_strength\" in col):\n",
    "                new_col = col.replace(\"home\",\"opponent\")\n",
    "                match_df = match_df.rename(columns={col: new_col})\n",
    "            if (\"away_ma\" in col) or (\"away_ca\" in col) or (\"away_elo_rate\" in col) or (\"pr_perc_away_win\" in col) or (\"away_strength\" in col):\n",
    "                new_col = col.replace(\"away\", \"team\")\n",
    "                match_df = match_df.rename(columns={col: new_col})\n",
    "    return match_df\n",
    "\n",
    "#### Calculating elo ####\n",
    "\n",
    "def calculate_elo_rating(elo_df,team_df):\n",
    "    k=30\n",
    "    team_elo_dict = dict()\n",
    "    elo_df['home_elo'] = 0\n",
    "    elo_df['away_elo'] = 0\n",
    "    \n",
    "    temp_df = pd.merge(team_df,elo_df, left_on='team_api_id',right_on = \"away_team_api_id\", how='inner')\n",
    "    team_list = temp_df.groupby(['team_api_id']).mean().reset_index()['team_api_id'].tolist()\n",
    "    \n",
    "    for team in team_list:\n",
    "        team_elo_dict[team]=1000\n",
    "    \n",
    "    for index, row in elo_df.iterrows():\n",
    "        home_team = row['home_team_api_id']\n",
    "        away_team = row['away_team_api_id']\n",
    "        match_result = row['result']\n",
    "        home_rating = team_elo_dict[home_team]\n",
    "        away_rating = team_elo_dict[away_team]\n",
    "        \n",
    "        \n",
    "        prob_home = 1.0 * 1.0 / (1 + 1.0 * math.pow(10, 1.0 * (away_rating - home_rating) / 400))\n",
    "        prob_away = 1.0 * 1.0 / (1 + 1.0 * math.pow(10, 1.0 * (home_rating - away_rating) / 400))\n",
    "        \n",
    "        if match_result == 1:\n",
    "            home_result=1\n",
    "            away_result=0\n",
    "        elif match_result == -1:\n",
    "            home_result=0\n",
    "            away_result=1\n",
    "        else:\n",
    "            home_result=0.5\n",
    "            away_result=0.5\n",
    "        \n",
    "        home_rating_new = round(home_rating + k*(home_result - prob_home))\n",
    "        away_rating_new = round(away_rating + k*(away_result - prob_away))\n",
    "        \n",
    "        if (home_rating_new < 0 or home_rating_new < 100):\n",
    "            home_rating_new = 100\n",
    "        if (away_rating_new < 0 or away_rating_new < 100):\n",
    "            away_rating_new = 100\n",
    "        \n",
    "        elo_df.at[index,'home_elo'] = home_rating_new\n",
    "        elo_df.at[index,'away_elo'] = away_rating_new\n",
    "        \n",
    "        team_elo_dict[home_team]= home_rating_new\n",
    "        team_elo_dict[away_team]= away_rating_new\n",
    "        \n",
    "    return elo_df\n",
    "\n",
    "\n",
    "def calculate_previous_games_results_goal_diff(pr_games_df, team_df):\n",
    "    \n",
    "    pr_games_df['pr_perc_home_win'] = 0.0\n",
    "    pr_games_df['pr_perc_draw'] = 0.0\n",
    "    pr_games_df['pr_perc_away_win'] = 0.0\n",
    "    pr_games_df['goals_diff'] = 0\n",
    "    temp_df = pd.merge(team_df,pr_games_df, left_on='team_api_id',right_on = \"away_team_api_id\", how='inner')\n",
    "    team_list = temp_df.groupby(['team_api_id']).mean().reset_index()['team_api_id'].tolist()\n",
    "    \n",
    "    temp_team_list = team_list.copy()\n",
    "    for team in team_list:\n",
    "        temp_team_list.remove(team)\n",
    "        for opponent in temp_team_list:\n",
    "            temp_df = pr_games_df.loc[((pr_games_df['home_team_api_id'] == team) & (pr_games_df['away_team_api_id'] == opponent))|\n",
    "                                      ((pr_games_df['home_team_api_id'] == opponent) & (pr_games_df['away_team_api_id'] == team))]\n",
    "            \n",
    "            if temp_df.empty:\n",
    "                continue\n",
    "            for index, row in temp_df.iterrows():\n",
    "                keep_win_dict = {team: 0, opponent: 0}\n",
    "                keep_goals_dict = {team: 0, opponent: 0}\n",
    "                team_percent = 0.0\n",
    "                opponent_percent = 0.0\n",
    "                draw_percent = 0.0\n",
    "                subset_temp_df = temp_df.loc[:index].copy()\n",
    "                subset_temp_df= subset_temp_df.drop(index)\n",
    "                \n",
    "                if not subset_temp_df.empty:\n",
    "                    \n",
    "                    for sub_index, sub_row in subset_temp_df.iloc[-5:].iterrows():\n",
    "                        \n",
    "                        if sub_row['result'] == 1:\n",
    "                            keep_win_dict[sub_row['home_team_api_id']] = keep_win_dict[sub_row['home_team_api_id']] + 1\n",
    "                        if sub_row['result'] == -1:\n",
    "                            keep_win_dict[sub_row['away_team_api_id']] = keep_win_dict[sub_row['away_team_api_id']] + 1\n",
    "                        ### for the goals ###    \n",
    "                        keep_goals_dict[sub_row['home_team_api_id']] = keep_goals_dict[sub_row['home_team_api_id']] + sub_row['home_team_goal']\n",
    "                        keep_goals_dict[sub_row['away_team_api_id']] = keep_goals_dict[sub_row['away_team_api_id']] + sub_row['away_team_goal']\n",
    "                        #####################\n",
    "                    team_percent = keep_win_dict[team] / len(subset_temp_df.iloc[-5:])\n",
    "                    opponent_percent = keep_win_dict[opponent] / len(subset_temp_df.iloc[-5:])\n",
    "                    draw_percent = 1 - (team_percent + opponent_percent)\n",
    "                    \n",
    "                    if team == row['home_team_api_id']:\n",
    "                        pr_games_df.at[index,'pr_perc_home_win'] = team_percent\n",
    "                        pr_games_df.at[index,'pr_perc_away_win'] = opponent_percent\n",
    "                        pr_games_df.at[index,'pr_perc_draw'] = draw_percent\n",
    "                    \n",
    "                    if team == row['away_team_api_id']:\n",
    "                        pr_games_df.at[index,'pr_perc_home_win'] = opponent_percent\n",
    "                        pr_games_df.at[index,'pr_perc_away_win'] = team_percent\n",
    "                        pr_games_df.at[index,'pr_perc_draw'] = draw_percent\n",
    "                        \n",
    "                    #### for the goals ###\n",
    "                    if team == row['home_team_api_id']:\n",
    "                        if keep_goals_dict[team] > keep_goals_dict[opponent]:\n",
    "                            pr_games_df.at[index,'goals_diff'] = keep_goals_dict[team] - keep_goals_dict[opponent]\n",
    "                        if keep_goals_dict[team] < keep_goals_dict[opponent]:\n",
    "                            pr_games_df.at[index,'goals_diff'] = keep_goals_dict[team] - keep_goals_dict[opponent]\n",
    "                            \n",
    "                    if team == row['away_team_api_id']:\n",
    "                        if keep_goals_dict[team] > keep_goals_dict[opponent]:\n",
    "                            pr_games_df.at[index,'goals_diff'] = keep_goals_dict[opponent] - keep_goals_dict[team]\n",
    "                        if keep_goals_dict[team] < keep_goals_dict[opponent]:\n",
    "                            pr_games_df.at[index,'goals_diff'] = keep_goals_dict[opponent] - keep_goals_dict[team]\n",
    "                    \n",
    "                        \n",
    "                               \n",
    "    return pr_games_df\n",
    "\n",
    "def add_strength_points_to_df(strength_df,joined_df):\n",
    "    strength_df['home_strength'] = np.nan\n",
    "    strength_df['away_strength'] = np.nan\n",
    "    for index, row in strength_df.iterrows():\n",
    "        home_team = row['home_team_api_id']\n",
    "        away_team = row['away_team_api_id']\n",
    "        current_season = row['season']\n",
    "        \n",
    "        for i in range(1,11):\n",
    "            change_current_season_format=\"until-\"+\"-\".join([str(int(year)-i) for year in current_season.split(\"/\")])\n",
    "\n",
    "            try:\n",
    "                home_strength=int(joined_df.loc[(joined_df['team_api_id'] == home_team) & (joined_df['Season'] == change_current_season_format)]['Strength'])\n",
    "                break\n",
    "            except:\n",
    "                home_strength = 0\n",
    "                continue\n",
    "        for i in range(1,11):\n",
    "            change_current_season_format=\"until-\"+\"-\".join([str(int(year)-i) for year in current_season.split(\"/\")])\n",
    "            try:\n",
    "                away_strength=int(joined_df.loc[(joined_df['team_api_id'] == away_team) & (joined_df['Season'] == change_current_season_format)]['Strength'])\n",
    "                break\n",
    "            except:\n",
    "                away_strength = 0\n",
    "                continue\n",
    "\n",
    "        strength_df.at[index,'home_strength'] = home_strength\n",
    "        strength_df.at[index,'away_strength'] = away_strength\n",
    "    return strength_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection\n",
    "cnx = sqlite3.connect(r'database.sqlite')\n",
    "# England id = 1729\n",
    "# Germany id = 7809\n",
    "match_df_england_raw = pd.read_sql_query(\"SELECT * FROM Match WHERE country_id == 1729\", cnx)\n",
    "\n",
    "\n",
    "\n",
    "match_df_england = match_df_england_raw.copy()\n",
    "team_df = pd.read_sql_query(\"SELECT * FROM Team\", cnx)\n",
    "match_df_england = drop_players_columns(match_df_england)\n",
    "match_df_england = keep_certain_bookeepers(match_df_england)\n",
    "\n",
    "match_df_england = match_df_england.dropna()\n",
    "match_df_england = create_class_label(match_df_england)\n",
    "match_df_england = calculate_total_goals(match_df_england)\n",
    "match_df_england = parse_xml_columns(match_df_england)\n",
    "\n",
    "#### ELO RATING ####\n",
    "match_df_for_elo = match_df_england.copy()\n",
    "elo_df_w_ratings = calculate_elo_rating(match_df_for_elo,team_df)\n",
    "match_df_england = elo_df_w_ratings\n",
    "#########################################\n",
    "\n",
    "###### Add previous game results and difference in goals ##############\n",
    "match_df_for_previous_games = match_df_england.copy()\n",
    "previous_games_results_df = calculate_previous_games_results_goal_diff(match_df_for_previous_games, team_df)\n",
    "match_df_england = previous_games_results_df\n",
    "#######################################################################\n",
    "\n",
    "##### Strength Team Dataframe Joined #################\n",
    "strength_df=pd.read_csv(r'strength_pl.csv')\n",
    "\n",
    "strength_team_join=pd.merge(team_df,strength_df, left_on='team_long_name',right_on = \"TeamName\", how='inner')\n",
    "match_df_for_strength = match_df_england.copy()\n",
    "match_df_england=add_strength_points_to_df(match_df_for_strength,strength_team_join)\n",
    "#################################################\n",
    "\n",
    "\n",
    "team_df_england = pd.merge(team_df,match_df_england, left_on='team_api_id',right_on = \"away_team_api_id\", how='inner')\n",
    "team_england_list = team_df_england.groupby(['team_api_id']).mean().reset_index()['team_api_id'].tolist()\n",
    "\n",
    "team_df_dict = calculate_ma_ca_elo(match_df_england,team_england_list)\n",
    "team_df_dict_shifted, ca_ma_col_names= shift_ma_ca_elo_columns(team_df_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_df_england_ca_ma = add_ca_ma_elo_col_to_main_df(team_df_dict_shifted, match_df_england,ca_ma_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_england_final = match_df_england_ca_ma.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_england_home = match_df_england_final.copy()\n",
    "match_df_england_away = match_df_england_final.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_england_home = create_unified_columns(match_df_england_home, is_home = True)\n",
    "match_df_england_away = create_unified_columns(match_df_england_away, is_home = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_df_england_final_concat = pd.concat([match_df_england_home,match_df_england_away],ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_df_england_train = match_df_england_final_concat.loc[(match_df_england_final_concat['season'] != '2014/2015') & (match_df_england_final_concat['season'] != '2015/2016')]\n",
    "match_df_england_test = match_df_england_final_concat.loc[(match_df_england_final_concat['season'] == '2014/2015') | (match_df_england_final_concat['season'] == '2015/2016')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = match_df_england_train.iloc[:,36:]\n",
    "Y_train = match_df_england_train['goals']\n",
    "X_test = match_df_england_test.iloc[:,36:]\n",
    "Y_test = match_df_england_test['goals']\n",
    "sc=StandardScaler()\n",
    "X_train_std=sc.fit_transform(X_train)\n",
    "X_test_std=sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pr_perc_draw', 'opponent_elo_rate', 'opponent_ma_goals', 'opponent_ma_sqrt_goals', 'opponent_ma_sqrt_shotons', 'opponent_ca_sqrt_shotoffs', 'opponent_ca_fouls', 'opponent_ma_pow2_fouls', 'opponent_ma_sqrt_fouls', 'opponent_ca_ycards', 'opponent_ca_sqrt_ycards', 'opponent_ca_crosses', 'opponent_ca_pow2_crosses', 'opponent_ca_sqrt_crosses', 'opponent_ca_pow2_possessions', 'opponent_ca_sqrt_possessions', 'team_elo_rate', 'team_ca_goals', 'team_ca_pow2_goals', 'team_ca_sqrt_goals', 'team_ma_sqrt_shotons', 'team_ma_pow2_shotoffs', 'team_ca_pow2_corners', 'team_ma_sqrt_corners', 'team_ca_possessions', 'homegame']\n"
     ]
    }
   ],
   "source": [
    "#Backward Elimination\n",
    "cols = list(X_train.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X_train[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(Y_train,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = np.max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_std_final=sc.fit_transform(X_train[selected_features_BE])\n",
    "X_test_std_final=sc.transform(X_test[selected_features_BE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Linear Reg ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_std_final, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test_std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9141313077022921\n",
      "Mean Squared Error: 1.3378917021292767\n",
      "Root Mean Squared Error: 1.1566726858231229\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test.values.ravel(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### XGBOOST ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'objective': 'reg:squaredlogerror', 'n_estimators': 60, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.9304522464087004\n",
      "The best regressor is: \n",
      "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.8, gamma=5, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=7,\n",
      "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=60, n_jobs=0, num_parallel_tree=1,\n",
      "             objective='reg:squaredlogerror', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "             validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "min_child_weight = [1, 5, 10]\n",
    "gamma =[0.5, 1, 1.5, 2, 5]\n",
    "subsample = [0.6, 0.8, 1.0]\n",
    "colsample_bytree = [0.6, 0.8, 1.0]\n",
    "max_depth = [int(x) for x in np.linspace(7, 100, num = 10)]\n",
    "objective=['reg:squaredlogerror','reg:squarederror']\n",
    "random_grid = {\n",
    "        'gamma': gamma,\n",
    "        'max_depth': max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"objective\": objective\n",
    "        }\n",
    "\n",
    "xgbr = xgb.XGBRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=xgbr,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='neg_mean_absolute_error',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 324 out of 324 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'colsample_bytree': 0.8, 'gamma': 2, 'max_depth': 4, 'min_child_weight': 10, 'n_estimators': 60, 'objective': 'reg:squaredlogerror'}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.9018850296811808\n",
      "The best regressor is: \n",
      "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
      "             min_child_weight=10, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=60, n_jobs=0, num_parallel_tree=1,\n",
      "             objective='reg:squaredlogerror', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "             validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "##########Grid Search CV ########\n",
    "n_estimators = [60]\n",
    "min_child_weight = [1, 5, 10]\n",
    "gamma =[ 2, 5,7]\n",
    "subsample = [0.8, 1.0,1.2]\n",
    "colsample_bytree = [ 0.8, 1.0,1.2]\n",
    "max_depth= [4, 5,7,10]\n",
    "objective = ['reg:squaredlogerror']\n",
    "        \n",
    "\n",
    "# Create the param grid\n",
    "param_grid = {\n",
    "        'gamma': gamma,\n",
    "        'max_depth': max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"objective\": objective\n",
    "        }\n",
    "\n",
    "# First create the base model to tune\n",
    "xgbr = xgb.XGBRegressor()\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgbr, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###XGBOOST #####\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=10, monotone_constraints=None,\n",
    "             n_estimators=60, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='reg:squaredlogerror', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "xg_reg.fit(X_train_std_final, Y_train.values.ravel())\n",
    "\n",
    "y_pred = xg_reg.predict(X_test_std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.905198842347149\n",
      "Mean Squared Error: 1.3808794674716272\n",
      "Root Mean Squared Error: 1.1751082790413943\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test.values.ravel(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Random Forest Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'n_estimators': 700, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 58, 'bootstrap': True}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.9316778607128452\n",
      "The best regressor is: \n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=58, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=4,\n",
      "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=700, n_jobs=None, oob_score=False,\n",
      "                      random_state=8, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "###### Random Search #####\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(7, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=rfr,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=10,\n",
    "                                   scoring='neg_mean_absolute_error',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'bootstrap': True, 'max_depth': 40, 'max_features': 'auto', 'min_samples_leaf': 6, 'min_samples_split': 15, 'n_estimators': 700}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.9180470451022872\n",
      "The best regressor is: \n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=6,\n",
      "                      min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=700, n_jobs=None, oob_score=False,\n",
      "                      random_state=8, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "bootstrap = [True]\n",
    "max_depth = [40, 50, 60,70]\n",
    "max_features = ['auto']\n",
    "min_samples_leaf = [4, 6]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [700]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfr = RandomForestRegressor(random_state=8)\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rfr, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "rfr = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=6,\n",
    "                      min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=700, n_jobs=None, oob_score=False,\n",
    "                      random_state=8, verbose=0, warm_start=False)\n",
    "rfr.fit(X_train_std_final, Y_train.values.ravel())\n",
    "\n",
    "y_pred = rfr.predict(X_test_std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9232996265496296\n",
      "Mean Squared Error: 1.362433038856878\n",
      "Root Mean Squared Error: 1.1672330696381412\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test.values.ravel(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### SVR #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'kernel': 'linear', 'gamma': 0.0001, 'degree': 3, 'C': 0.01}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.9125926026337945\n",
      "The best regressor is: \n",
      "SVR(C=0.01, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0001,\n",
      "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#### Random Search ######\n",
    "\n",
    "# C\n",
    "C = [.0001, .001, .01]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "\n",
    "# degree\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree\n",
    "             }\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=svr,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='neg_mean_absolute_error',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   36.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "The mae of a model with these hyperparameters is:\n",
      "-0.8931900689810494\n",
      "The best regressor is: \n",
      "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "###### Grid Search ######\n",
    "\n",
    "# C\n",
    "C = [.001, .01,1]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01]\n",
    "\n",
    "# degree\n",
    "degree = [2, 3, 4]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = [\n",
    "  {'C': C, 'kernel':['linear']},\n",
    "  {'C': C, 'kernel':['poly'], 'degree':degree},\n",
    "  {'C': C, 'kernel':['rbf'], 'gamma':gamma}\n",
    "]\n",
    "\n",
    "# Create a base model\n",
    "svr = SVR()\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svr, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_std_final, Y_train.values.ravel())\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mae of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)\n",
    "print(\"The best regressor is: \")\n",
    "print(grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr = SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001,\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "svr.fit(X_train_std_final, Y_train.values.ravel())\n",
    "y_pred = svr.predict(X_test_std_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9008437659147246\n",
      "Mean Squared Error: 1.332789928397513\n",
      "Root Mean Squared Error: 1.154465213160411\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_test.values.ravel(), y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test.values.ravel(), y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
